{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949b9315",
   "metadata": {},
   "source": [
    "# RAG (retrieval-augmented-generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2aa77",
   "metadata": {},
   "source": [
    "### Importaciones \n",
    "Para este proyecto, necesitamos las siguientes dependencias:\n",
    "\n",
    "1. streamlit\n",
    "2. ollama\n",
    "3. langchain\n",
    "4. langchain-community\n",
    "5. langchain-core\n",
    "6. langchain-ollama\n",
    "7. langchain-text-splitters\n",
    "7. chromadb\n",
    "8. pdfplumber\n",
    "9. pypdf\n",
    "\n",
    "` pip install streamlit ollama langchain langchain-community langchain-core langchain-ollama langchain-text-splitters chromadb pdfplumber pypdf `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec3a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import embeddings\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27070c",
   "metadata": {},
   "source": [
    "### Template\n",
    "Generamos nuestro template, es muy importante ser precisos y muy descriptivos con lo que necesitamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_template = \"\"\"\n",
    "\n",
    "Eres un asistente experto en análisis de libros en PDF.\n",
    "\n",
    "Tu tarea:\n",
    "- Leer el contenido proporcionado.\n",
    "- Responder únicamente lo que se te pregunte, basándote solo en ese contenido.\n",
    "- Si el contenido no es suficiente para responder con certeza, di que no tienes suficiente información.\n",
    "\n",
    "Reglas:\n",
    "\n",
    "Para responder debes seguir lo siguente:\n",
    "\n",
    "Contexto: {context}\n",
    "Pregunta: {question}\n",
    "Mensajes Anteriores: {historial}\n",
    "\n",
    "- No inventes, no agregues conocimiento externo.\n",
    "- No asumas nada que no esté explícitamente en el texto.\n",
    "- Siempre responde en español.\n",
    "\n",
    "Tipos de pedidos posibles:\n",
    "- Preguntas sobre el contenido del libro.\n",
    "- Solicitudes de resumen de capítulos o fragmentos.\n",
    "\n",
    "Importante:\n",
    "- Si el usuario pide un resumen, genera uno breve y claro del contenido proporcionado.\n",
    "- Si el usuario hace una pregunta, respóndela directamente, sin rodeos ni explicaciones innecesarias.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd98af",
   "metadata": {},
   "source": [
    "### Crear un directorio para los pdfs \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf72b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs_directory = \"./pdfs\"\n",
    "db_directory = \"./vector_db\"\n",
    "if not os.path.exists(db_directory):\n",
    "    os.makedirs(db_directory)\n",
    "if not os.path.exists(pdfs_directory):\n",
    "    os.makedirs(pdfs_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11de766",
   "metadata": {},
   "source": [
    "La libreria de ollama, provee un modelo de embeddings para generar embeddings de texto y un modelo de LLM para generar respuestas a preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ecd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vector_store = Chroma(persist_directory=db_directory, embedding_function=embeddings)\n",
    "model = OllamaLLM(model=\"phi4-mini:3.8b-q4_K_M\", temperature=0.4, max_tokens=2000, stream = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa05ef",
   "metadata": {},
   "source": [
    "### Cargar el PDF y dividirlo en fragmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cb3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf(file):\n",
    "    with open(pdfs_directory + file.name, \"wb\") as f:\n",
    "        f.write(file.getbuffer())\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    loader = PDFPlumberLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775fe12",
   "metadata": {},
   "source": [
    "### Dividimos el contenido en chunks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para. dividir el contenido\n",
    "def text_splitter(documents, book_name=None):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    if book_name:\n",
    "        for chunk in chunks:\n",
    "            chunk.page_content = f\"Libro: {book_name}\\n{chunk.page_content}\"\n",
    "    return chunks\n",
    "\n",
    "#Funcion para guardar en la memoria.\n",
    "def index_docs(documents):\n",
    "    vector_store.add_documents(documents)\n",
    "    vector_store.persist()\n",
    "    \n",
    "#Funcion para devolver contenido relacionado a la pregunta del usuario\n",
    "def retrieve_docs(query, book_name=None):\n",
    "    docs = vector_store.similarity_search(query, k=10) \n",
    "    if book_name:\n",
    "        docs = [doc for doc in docs if doc.metadata.get(\"book_name\") == book_name]\n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc1a57",
   "metadata": {},
   "source": [
    "### Generar la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2329739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para generar la respuesta.\n",
    "\n",
    "def generate_response_stream(contexto, book_name):\n",
    "    prompt = ChatPromptTemplate.from_template(custom_template)\n",
    "    chain = prompt | model\n",
    "\n",
    "    response_stream = chain.stream({\n",
    "        \"contexto\": contexto,\n",
    "        \"book_name\":book_name,\n",
    "    })\n",
    "\n",
    "    return response_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ba9b8",
   "metadata": {},
   "source": [
    "### Obtener el hash de los pdfs subidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(file_path):\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        buf = f.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def is_pdf_already_indexed(file_hash):\n",
    "    result = vector_store.similarity_search(file_hash, k=1)\n",
    "    if result:\n",
    "        for doc in result:\n",
    "            if doc.metadata.get(\"file_hash\") == file_hash:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab58ec",
   "metadata": {},
   "source": [
    "### Generar una interfaz con streamlit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09825a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uploaded_file = st.file_uploader(\"Sube un PDF\", type=\"pdf\", accept_multiple_files=False)\n",
    "book_name = st.text_input(\"Nombre del libro\")\n",
    "\n",
    "#Verfiicar si el pdf ya fue indexado\n",
    "if uploaded_file and book_name:\n",
    "    upload_pdf(uploaded_file)\n",
    "    documents = load_pdf(pdfs_directory + uploaded_file.name)\n",
    "\n",
    "    file_hash = get_file_hash(pdfs_directory + uploaded_file.name)\n",
    "    if is_pdf_already_indexed(file_hash):\n",
    "        st.warning(\"Este PDF ya ha sido indexado.\")\n",
    "    else:\n",
    "        st.success(\"PDF subido y procesado correctamente.\")\n",
    "        \n",
    "\n",
    "\n",
    "    chunked_documents = text_splitter(documents)\n",
    "    for doc in chunked_documents:\n",
    "        doc.metadata[\"file_hash\"] = file_hash\n",
    "        doc.metadata[\"book_name\"] = book_name\n",
    "\n",
    "    index_docs(chunked_documents)\n",
    "\n",
    "book_name = st.text_input(\"Nombre del libro\")\n",
    "    \n",
    "\n",
    "if book_name != \"\":\n",
    "    st.chat_message(\"user\").write(f\"Título del libro: {book_name}\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # 2. Recuperar contexto relevante (si existe)\n",
    "    related_documents = retrieve_docs( book_name)\n",
    "\n",
    "    # Extraer el texto de cada Document\n",
    "    contexto = \"\\n\".join(doc.page_content for doc in related_documents) if related_documents else \"\"\n",
    "    # 3. Armar el prompt rellenando el template\n",
    "    prompt = custom_template.format(\n",
    "        book_name= book_name,\n",
    "        contexto=contexto,\n",
    "    )\n",
    "\n",
    "    # 4. Generar respuesta\n",
    "    message_placeholder = st.chat_message(\"assistant\").empty()\n",
    "    full_response = \"\"\n",
    "\n",
    "    for chunk in generate_response_stream(contexto, book_name):\n",
    "        full_response += chunk  # cada chunk trae parte del texto\n",
    "        message_placeholder.markdown(full_response)  # vamos actualizando\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
